from __future__ import annotations

from typing import Dict, Iterable, List, Optional, Sequence, Tuple
from types import ModuleType

class Tensor:
    def __init__(self, rows: int, cols: int, data: Optional[Sequence[float]] = ...) -> None: ...
    @staticmethod
    def zeros(rows: int, cols: int) -> Tensor: ...
    @staticmethod
    def from_dlpack(capsule: object) -> Tensor: ...
    def to_dlpack(self) -> object: ...
    def __dlpack__(self, *, stream: object | None = ...) -> object: ...
    def __dlpack_device__(self) -> tuple[int, int]: ...
    @property
    def rows(self) -> int: ...
    @property
    def cols(self) -> int: ...
    def shape(self) -> tuple[int, int]: ...
    def tolist(self) -> List[List[float]]: ...

class ComplexTensor:
    def __init__(self, rows: int, cols: int, data: Optional[Sequence[complex]] = ...) -> None: ...
    @staticmethod
    def zeros(rows: int, cols: int) -> ComplexTensor: ...
    def shape(self) -> tuple[int, int]: ...
    def to_tensor(self) -> Tensor: ...
    def data(self) -> List[complex]: ...
    def matmul(self, other: ComplexTensor) -> ComplexTensor: ...

class OpenCartesianTopos:
    def __init__(
        self,
        curvature: float,
        tolerance: float,
        saturation: float,
        max_depth: int,
        max_volume: int,
    ) -> None: ...
    def curvature(self) -> float: ...
    def tolerance(self) -> float: ...
    def saturation(self) -> float: ...
    def max_depth(self) -> int: ...
    def max_volume(self) -> int: ...
    def ensure_loop_free(self, depth: int) -> None: ...
    def saturate(self, value: float) -> float: ...

class LanguageWaveEncoder:
    def __init__(self, curvature: float, temperature: float) -> None: ...
    def curvature(self) -> float: ...
    def temperature(self) -> float: ...
    def encode_wave(self, text: str) -> ComplexTensor: ...
    def encode_z_space(self, text: str) -> Tensor: ...

class GradientSummary:
    def l1(self) -> float: ...
    def l2(self) -> float: ...
    def linf(self) -> float: ...
    def count(self) -> int: ...
    def mean_abs(self) -> float: ...
    def rms(self) -> float: ...
    def sum_squares(self) -> float: ...

class Hypergrad:
    def __init__(self, curvature: float, learning_rate: float, rows: int, cols: int) -> None: ...
    def curvature(self) -> float: ...
    def learning_rate(self) -> float: ...
    def shape(self) -> tuple[int, int]: ...
    def gradient(self) -> List[float]: ...
    def summary(self) -> GradientSummary: ...
    def scale_learning_rate(self, factor: float) -> None: ...
    def reset(self) -> None: ...
    def retune(self, curvature: float, learning_rate: float) -> None: ...
    def accumulate_wave(self, tensor: Tensor) -> None: ...
    def accumulate_complex_wave(self, wave: ComplexTensor) -> None: ...
    def absorb_text(self, encoder: LanguageWaveEncoder, text: str) -> None: ...
    def accumulate_pair(self, prediction: Tensor, target: Tensor) -> None: ...
    def apply(self, weights: Tensor) -> None: ...
    def topos(self) -> OpenCartesianTopos: ...

class TensorBiome:
    def __init__(self, topos: OpenCartesianTopos) -> None: ...
    def topos(self) -> OpenCartesianTopos: ...
    def len(self) -> int: ...
    def __len__(self) -> int: ...
    def is_empty(self) -> bool: ...
    def total_weight(self) -> float: ...
    def weights(self) -> List[float]: ...
    def absorb(self, tensor: Tensor) -> None: ...
    def absorb_weighted(self, tensor: Tensor, weight: float) -> None: ...
    def clear(self) -> None: ...
    def canopy(self) -> Tensor: ...

def from_dlpack(capsule: object) -> Tensor: ...

def to_dlpack(tensor: Tensor) -> object: ...

class _CompatTorch(ModuleType):
    def to_torch(tensor: Tensor) -> object: ...
    def from_torch(tensor: object) -> Tensor: ...

class _CompatJax(ModuleType):
    def to_jax(tensor: Tensor) -> object: ...
    def from_jax(array: object) -> Tensor: ...

class _CompatTensorFlow(ModuleType):
    def to_tensorflow(tensor: Tensor) -> object: ...
    def from_tensorflow(value: object) -> Tensor: ...

class _CompatNamespace(ModuleType):
    torch: _CompatTorch
    jax: _CompatJax
    tensorflow: _CompatTensorFlow

compat: _CompatNamespace

def set_global_seed(seed: int) -> None: ...

def golden_ratio() -> float: ...

def golden_angle() -> float: ...

def fibonacci_pacing(total_steps: int) -> List[int]: ...

def pack_nacci_chunks(order: int, total_steps: int) -> List[int]: ...

def pack_tribonacci_chunks(total_steps: int) -> List[int]: ...

def pack_tetranacci_chunks(total_steps: int) -> List[int]: ...

def generate_plan_batch_ex(
    n: int,
    total_steps: int,
    base_radius: float,
    radial_growth: float,
    base_height: float,
    meso_gain: float,
    micro_gain: float,
    seed: Optional[int] = ...,
) -> List[object]: ...


class _NnDataset:
    def __init__(self) -> None: ...

    @staticmethod
    def from_pairs(samples: Sequence[Tuple[Tensor, Tensor]]) -> _NnDataset: ...

    def push(self, input: Tensor, target: Tensor) -> None: ...

    def len(self) -> int: ...

    def is_empty(self) -> bool: ...

    def loader(self) -> _NnDataLoader: ...

    def __len__(self) -> int: ...


class _NnDataLoader:
    def len(self) -> int: ...

    def __len__(self) -> int: ...

    def is_empty(self) -> bool: ...

    def batch_size(self) -> int: ...

    def prefetch_depth(self) -> int: ...

    def shuffle(self, seed: int) -> _NnDataLoader: ...

    def batched(self, batch_size: int) -> _NnDataLoader: ...

    def dynamic_batch_by_rows(self, max_rows: int) -> _NnDataLoader: ...

    def prefetch(self, depth: int) -> _NnDataLoader: ...

    def iter(self) -> _NnDataLoaderIter: ...

    def __iter__(self) -> _NnDataLoaderIter: ...


class _NnDataLoaderIter(Iterable[Tuple[Tensor, Tensor]]):
    def __iter__(self) -> _NnDataLoaderIter: ...

    def __next__(self) -> Tuple[Tensor, Tensor]: ...


class _NnModule(ModuleType):
    Dataset: type[_NnDataset]
    DataLoader: type[_NnDataLoader]
    DataLoaderIter: type[_NnDataLoaderIter]

    def from_samples(samples: Sequence[Tuple[Tensor, Tensor]]) -> _NnDataLoader: ...


nn: _NnModule


class _FracModule(ModuleType):
    def gl_coeffs_adaptive(alpha: float, tol: float = ..., max_len: int = ...) -> List[float]: ...

    def fracdiff_gl_1d(
        x: Sequence[float],
        alpha: float,
        kernel_len: int,
        pad: str = ...,
        pad_constant: Optional[float] = ...,
        scale: Optional[float] = ...,
    ) -> List[float]: ...


frac: _FracModule

dataset: ModuleType

linalg: ModuleType

rl: ModuleType

rec: ModuleType

telemetry: ModuleType

ecosystem: ModuleType

class QueryPlan:
    def __init__(self, query: str) -> None: ...
    @property
    def query(self) -> str: ...
    def selects(self) -> List[str]: ...
    def limit(self) -> Optional[int]: ...
    def order(self) -> Optional[Tuple[str, str]]: ...
    def filters(self) -> List[Tuple[str, str, float]]: ...

class RecEpochReport:
    rmse: float
    samples: int
    regularization_penalty: float

class Recommender:
    def __init__(self, users: int, items: int, factors: int, learning_rate: float = ..., regularization: float = ..., curvature: float = ...) -> None: ...
    def predict(self, user: int, item: int) -> float: ...
    def train_epoch(self, ratings: Sequence[Tuple[int, int, float]]) -> RecEpochReport: ...
    def recommend_top_k(self, user: int, k: int, exclude: Optional[Sequence[int]] = ...) -> List[Tuple[int, float]]: ...
    def recommend_query(
        self, user: int, query: QueryPlan, exclude: Optional[Sequence[int]] = ...
    ) -> List[Dict[str, float]]: ...
    def user_embedding(self, user: int) -> Tensor: ...
    def item_embedding(self, item: int) -> Tensor: ...
    @property
    def users(self) -> int: ...
    @property
    def items(self) -> int: ...
    @property
    def factors(self) -> int: ...

class DqnAgent:
    def __init__(self, state_dim: int, action_dim: int, discount: float, learning_rate: float) -> None: ...
    def select_action(self, state: int) -> int: ...
    def update(self, state: int, action: int, reward: float, next_state: int) -> None: ...

class PpoAgent:
    def __init__(self, state_dim: int, action_dim: int, learning_rate: float, clip_range: float) -> None: ...
    def score_actions(self, state: Sequence[float]) -> List[float]: ...
    def value(self, state: Sequence[float]) -> float: ...
    def update(self, state: Sequence[float], action: int, advantage: float, old_log_prob: float) -> None: ...

class SacAgent:
    def __init__(self, state_dim: int, action_dim: int, temperature: float) -> None: ...
    def sample_action(self, state: Sequence[float]) -> int: ...
    def jitter(self, entropy_target: float) -> None: ...

class DashboardMetric:
    name: str
    value: float
    unit: Optional[str]
    trend: Optional[float]

class DashboardEvent:
    message: str
    severity: str

class DashboardFrame:
    timestamp: float
    metrics: List[DashboardMetric]
    events: List[DashboardEvent]

class DashboardRing:
    def __init__(self, capacity: int) -> None: ...
    def push(self, frame: DashboardFrame) -> None: ...
    def latest(self) -> Optional[DashboardFrame]: ...
    def __iter__(self) -> Iterable[DashboardFrame]: ...

__all__ = [
    "Tensor",
    "from_dlpack",
    "to_dlpack",
    "nn",
    "frac",
    "dataset",
    "linalg",
    "rl",
    "rec",
    "telemetry",
    "ecosystem",
    "compat",
    "set_global_seed",
    "golden_ratio",
    "golden_angle",
    "fibonacci_pacing",
    "pack_nacci_chunks",
    "pack_tribonacci_chunks",
    "pack_tetranacci_chunks",
    "generate_plan_batch_ex",
    "gl_coeffs_adaptive",
    "fracdiff_gl_1d",
    "QueryPlan",
    "RecEpochReport",
    "Recommender",
    "DqnAgent",
    "PpoAgent",
    "SacAgent",
    "DashboardMetric",
    "DashboardEvent",
    "DashboardFrame",
    "DashboardRing",
]
