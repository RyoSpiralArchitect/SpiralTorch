name: Release Wheels

on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:
    inputs:
      publish_pypi:
        description: "Publish wheels to PyPI (otherwise manual upload)"
        required: false
        default: false
        type: boolean

permissions:
  actions: read
  contents: write
  id-token: write

jobs:
  wheels:
    name: Build ${{ matrix.label }} / py${{ matrix.py }}
    runs-on: ${{ matrix.os }}
    defaults:
      run:
        shell: bash
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-22.04
            label: ubuntu-22.04
            macos_deployment_target: ""
            universal2: false
            py: "3.12"
          - os: macos-latest
            label: macos-latest-macosx14-universal2
            macos_deployment_target: "14.0"
            universal2: true
            py: "3.12"
          - os: windows-2022
            label: windows-2022
            macos_deployment_target: ""
            universal2: false
            py: "3.12"
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.py }}
      - name: Set macOS deployment target
        if: matrix.macos_deployment_target != ''
        run: echo "MACOSX_DEPLOYMENT_TARGET=${{ matrix.macos_deployment_target }}" >> "$GITHUB_ENV"
      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
      - name: Install macOS universal2 targets
        if: runner.os == 'macOS' && matrix.universal2 == true
        run: rustup target add aarch64-apple-darwin x86_64-apple-darwin
      - name: Build wheels (CPU+WGPU, manylinux2014)
        run: |
          if [ "${{ runner.os }}" = "Linux" ]; then
            python -m pip install -U pip wheel "maturin[zig]"
          else
            python -m pip install -U pip wheel maturin
          fi

          extra_args=""
          if [ "${{ runner.os }}" = "macOS" ] && [ "${{ matrix.universal2 }}" = "true" ]; then
            extra_args="$extra_args --target universal2-apple-darwin"
          fi
          if [ "${{ runner.os }}" = "Linux" ]; then
            maturin build -m bindings/st-py/Cargo.toml --release --locked --compatibility manylinux2014 --zig --features wgpu,logic,kdsl
          else
            maturin build -m bindings/st-py/Cargo.toml --release --locked $extra_args --features wgpu,logic,kdsl
          fi
      - name: Smoke test wheel import
        shell: bash
        working-directory: target/wheels
        env:
          PYTHONNOUSERSITE: "1"
        run: |
          python -m pip install --force-reinstall --no-cache-dir spiraltorch-*.whl
          python - <<'PY'
          import spiraltorch as st

          print("import ok:", len(getattr(st, "__all__", ())))
          assert hasattr(st, "optim")
          assert hasattr(st.optim, "Amegagrad")

          opt = st.optim.Amegagrad((1, 3), curvature=-0.9, hyper_learning_rate=0.03, real_learning_rate=0.02)
          weights = st.Tensor(1, 3, [0.2, -0.1, 0.05])
          opt.accumulate_wave(st.Tensor(1, 3, [0.4, -0.6, 0.2]))
          before = weights.tolist()
          opt.step(weights, tune=False)
          after = weights.tolist()
          assert after != before

          trainer = st.ZSpaceTrainer(z_dim=4)
          loss = trainer.step(
              {"speed": 0.2, "memory": 0.1, "stability": 0.9, "gradient": opt.real.gradient()}
          )
          float(loss)
          partial_loss = trainer.step_partial(
              {"speed": 0.15, "memory": 0.1, "stability": 0.92, "gradient": [0.1, 0.0, 0.0, 0.0]}
          )
          float(partial_loss)
          assert trainer.last_inference is not None

          assert hasattr(st, "LanguageWaveEncoder")
          encoder = st.LanguageWaveEncoder(-1.0, 0.5)
          probe = encoder.encode_z_space("SpiralTorch")
          rows, cols = probe.shape()
          text_opt = st.optim.Amegagrad((rows, cols), curvature=float(encoder.curvature()))
          text_weights = st.Tensor(rows, cols, [0.0] * (rows * cols))
          text_opt.absorb_text(encoder, "SpiralTorch wheels smoke test")
          before = text_weights.tolist()
          control = text_opt.desire_control()
          text_opt.step(text_weights, tune=True, control=control)
          after = text_weights.tolist()
          assert after != before

          info = st.build_info()
          assert isinstance(info, dict)
          assert info.get("package") == "spiraltorch-py"

          projector = st.canvas.CanvasProjector(width=16, height=16, palette="turbo")
          projector.push_patch(st.Tensor(16, 16, [0.0] * 256), coherence=1.0, tension=1.0, depth=0)
          projector.refresh_rgba()
          patch = projector.emit_zspace_patch(coherence=1.0, tension=1.0, depth=0)
          assert patch["relation"].shape() == (16, 16)
          projector.push_patch(patch["relation"], coherence=patch["coherence"], tension=patch["tension"], depth=patch["depth"])
          trail = projector.emit_wasm_trail(curvature=1.5)
          assert trail["samples"].shape() == (16 * 16, 7)
          frame = projector.emit_atlas_frame(prefix="canvas", refresh=False, timestamp=0.0)
          assert isinstance(frame.timestamp, float)

          patch_packet = st.canvas.emit_zspace_patch_packet(projector, coherence=1.0, tension=1.0, depth=0)
          assert patch_packet.relation.shape() == (16, 16)
          trail_packet = st.canvas.emit_wasm_trail_packet(projector, curvature=1.5)
          assert trail_packet.samples.shape() == (16 * 16, 7)

          route = st.telemetry.AtlasRoute()
          route.push_bounded(st.telemetry.AtlasFrame.from_metrics({"psi.total": 1.0}, timestamp=0.0), bound=8)
          route.push_bounded(st.telemetry.AtlasFrame.from_metrics({"psi.total": 1.5}, timestamp=1.0), bound=8)
          route.push_bounded(frame, bound=8)
          assert route.perspective_for("Concourse", focus_prefixes=["psi."]) is not None
          assert isinstance(route.beacons(limit=4), list)
          perspective_packet = st.telemetry.perspective_for_packet(route, "Concourse", focus_prefixes=["psi."])
          assert perspective_packet is not None
          assert isinstance(perspective_packet.guidance, str)

          session = st.amegagrad_session((1, 4), curvature=-0.9, telemetry=True, telemetry_bound=8)
          session.step_wave(st.Tensor(1, 4, [0.1, -0.2, 0.05, 0.0]))

          print("smoke ok")
          PY
      - name: Upload wheels (artifact)
        uses: actions/upload-artifact@v6
        with:
          name: wheels-${{ matrix.label }}-py${{ matrix.py }}
          path: target/wheels/*.whl

  pypi:
    name: Publish wheels to PyPI
    needs: wheels
    if: github.event_name == 'workflow_dispatch' && inputs.publish_pypi == 'true'
    runs-on: ubuntu-22.04
    environment:
      name: pypi
      url: https://pypi.org/p/spiraltorch
    permissions:
      actions: read
      contents: read
      id-token: write
    steps:
      - uses: actions/download-artifact@v4
        with:
          path: dist
      - name: Collect wheels
        run: |
          set -euo pipefail
          mkdir -p pypi_dist
          find dist -type f -name '*.whl' -print0 | sort -z | xargs -0 -I{} cp "{}" pypi_dist/
          ls -la pypi_dist
      - name: Publish to PyPI (token)
        if: secrets.PYPI_API_TOKEN != ''
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: pypi_dist
          password: ${{ secrets.PYPI_API_TOKEN }}
      - name: Publish to PyPI (trusted publishing)
        if: secrets.PYPI_API_TOKEN == ''
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: pypi_dist

  attach:
    name: Attach wheels to GitHub Release
    needs: wheels
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
      - uses: actions/download-artifact@v4
        with:
          path: dist
      - name: Generate checksums for release wheels
        run: |
          set -euo pipefail
          find dist -type f -name '*.whl' -print0 | sort -z | xargs -0 -I{} sh -c 'sha256sum "{}" | sed "s|  .*|  $(basename "{}")|"' > dist/wheels.sha256
          find dist -type f -name '*.whl' -print0 | sort -z | xargs -0 -I{} sh -c 'sha512sum "{}" | sed "s|  .*|  $(basename "{}")|"' > dist/wheels.sha512
      - name: Snapshot repository manifest and compliance seal
        run: |
          python scripts/security/generate_repo_manifest.py \
            --repo-root . \
            --canonical-license "LICENSE .txt" \
            --output dist/spiraltorch-repo-license-manifest.json \
            --allow-untracked
          python scripts/security/generate_compliance_seal.py \
            --manifest dist/spiraltorch-repo-license-manifest.json \
            --repo-root . \
            --output dist/spiraltorch-compliance-seal.json
      - name: Enforce embedded AGPL license payloads
        env:
          RELEASE_TAG: ${{ github.ref_name }}
        run: |
          python scripts/security/generate_license_report.py \
            --dist dist \
            --license "LICENSE .txt" \
            --tag "$RELEASE_TAG"
      - name: Generate SBOM for release payload
        uses: anchore/sbom-action@v0.20.9
        with:
          path: dist
          format: cyclonedx-json
          output-file: dist/spiraltorch-${{ github.ref_name }}-sbom.cdx.json
          artifact-name: spiraltorch-${{ github.ref_name }}-sbom
          upload-release-assets: false
      - name: Generate authenticated release manifest
        env:
          RELEASE_TAG: ${{ github.ref_name }}
        run: |
          python - <<'PY'
          import hashlib
          import json
          import os
          from datetime import datetime, timezone
          from pathlib import Path

          base = Path("dist")
          tag = os.environ["RELEASE_TAG"]

          def digest(path: Path, algorithm: str) -> str:
              h = hashlib.new(algorithm)
              with path.open("rb") as fh:
                  for chunk in iter(lambda: fh.read(1024 * 1024), b""):
                      h.update(chunk)
              return h.hexdigest()

          files = []
          for path in sorted(
              p for p in base.rglob("*") if p.is_file() and p.suffix not in {".sig", ".crt", ".intoto", ".jsonl"}
          ):
              sha256 = digest(path, "sha256")
              sha512 = digest(path, "sha512")

              files.append(
                  {
                      "asset": path.name,
                      "source_path": path.as_posix(),
                      "size": path.stat().st_size,
                      "sha256": sha256,
                      "sha512": sha512,
                  }
              )

          manifest = {
              "schema": "https://spiraltorch.org/security/release-manifest/v1",
              "tag": tag,
              "generated_at": datetime.now(tz=timezone.utc).isoformat(),
              "workflow": "Release Wheels",
              "files": files,
          }

          output = base / f"spiraltorch-{tag}-manifest.json"
          output.write_text(json.dumps(manifest, indent=2, sort_keys=True) + "\n", encoding="utf-8")
          PY
      - name: Generate SLSA provenance for wheels
        uses: actions/attest-build-provenance@v3
        with:
          subject-path: 'dist/**/*.whl'
      - name: Sign release artifacts with Sigstore
        uses: sigstore/gh-action-sigstore@v2.3.1
        with:
          inputs: |
            dist/**/*.whl
            dist/*.sha256
            dist/*.sha512
            dist/*.json
            dist/spiraltorch-repo-license-manifest.json
            dist/spiraltorch-compliance-seal.json
      - name: Create/Update GitHub Release with assets
        uses: softprops/action-gh-release@v2
        with:
          files: |
            dist/**/*
