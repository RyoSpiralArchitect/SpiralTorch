//! High-order differential structures that weave together homotopies, functors,
//! recursive barycenter flows, and \(\infty\)-categorical towers.
//!
//! The intent is not to mimic classical \(\partial f/\partial x\) operators but
//! to expose the "movement" primitives SpiralTorch already leans on: Z-space
//! barycenters, open-cartesian toposes, and hypergrad tapes.  Each component is
//! intentionally composable so higher layers can trace an activation through the
//! homotopy gate, lift it across a functor, fold in the barycentric energy
//! trail, and finally stitch the result across a tower of curvatures.

use super::measure::{BarycenterIntermediate, ZSpaceBarycenter};
use super::{AmegaHypergrad, OpenCartesianTopos, PureResult, Tensor, TensorError};

/// Non-commutative differential generated by a homotopy action.
#[derive(Clone, Debug)]
pub struct HomotopyDifferential {
    seed: Tensor,
    generator: Tensor,
    direction: Tensor,
}

impl HomotopyDifferential {
    /// Creates a new homotopy differential. All tensors must share the same shape.
    pub fn new(seed: Tensor, generator: Tensor, direction: Tensor) -> PureResult<Self> {
        let seed_shape = seed.shape();
        if generator.shape() != seed_shape {
            return Err(TensorError::ShapeMismatch {
                left: generator.shape(),
                right: seed_shape,
            });
        }
        if direction.shape() != seed_shape {
            return Err(TensorError::ShapeMismatch {
                left: direction.shape(),
                right: seed_shape,
            });
        }
        Ok(Self {
            seed,
            generator,
            direction,
        })
    }

    /// Returns the seed tensor the flow anchors on.
    pub fn seed(&self) -> &Tensor {
        &self.seed
    }

    /// Returns the direction tensor used for the Hadamard lift.
    pub fn direction(&self) -> &Tensor {
        &self.direction
    }

    /// Applies the generator to the provided state.
    pub fn flow_from(&self, state: &Tensor) -> PureResult<Tensor> {
        if state.shape() != self.seed.shape() {
            return Err(TensorError::ShapeMismatch {
                left: state.shape(),
                right: self.seed.shape(),
            });
        }
        let delta = self.generator.hadamard(&self.direction)?;
        state.add(&delta)
    }

    /// Applies the generator to the internal seed.
    pub fn flow(&self) -> PureResult<Tensor> {
        self.flow_from(&self.seed)
    }

    /// Applies the generator and rewrites the result through the provided topos.
    pub fn flow_guarded(&self, topos: &OpenCartesianTopos) -> PureResult<Tensor> {
        let mut candidate = self.flow()?;
        topos.saturate_slice(candidate.data_mut());
        topos.guard_tensor("homotopy_flow", &candidate)?;
        Ok(candidate)
    }

    /// Evaluates the commutator with another homotopy differential using the seed.
    pub fn commutator(
        &self,
        other: &HomotopyDifferential,
        topos: Option<&OpenCartesianTopos>,
    ) -> PureResult<Tensor> {
        if self.seed.shape() != other.seed.shape() {
            return Err(TensorError::ShapeMismatch {
                left: self.seed.shape(),
                right: other.seed.shape(),
            });
        }
        let first = self.flow()?;
        let forward = other.flow_from(&first)?;
        let second = other.flow()?;
        let backward = self.flow_from(&second)?;
        let mut commutator = forward.sub(&backward)?;
        if let Some(topos) = topos {
            topos.saturate_slice(commutator.data_mut());
            topos.guard_tensor("homotopy_commutator", &commutator)?;
        }
        Ok(commutator)
    }

    /// Squared energy of the generator-direction coupling.
    pub fn directional_energy(&self) -> PureResult<f32> {
        Ok(self.generator.hadamard(&self.direction)?.squared_l2_norm())
    }
}

/// Differential acting on functionals through an internal kernel (functor lift).
#[derive(Clone, Debug)]
pub struct FunctorDifferential {
    source: Tensor,
    kernel: Tensor,
    epsilon: f32,
}

impl FunctorDifferential {
    /// Builds a new functor differential. `epsilon` is the step used for linearisation.
    pub fn new(source: Tensor, kernel: Tensor, epsilon: f32) -> PureResult<Self> {
        if epsilon <= 0.0 || !epsilon.is_finite() {
            return Err(TensorError::NonPositiveLearningRate { rate: epsilon });
        }
        if source.shape().1 != kernel.shape().0 {
            return Err(TensorError::ShapeMismatch {
                left: source.shape(),
                right: kernel.shape(),
            });
        }
        Ok(Self {
            source,
            kernel,
            epsilon,
        })
    }

    /// Returns the linearisation step.
    pub fn epsilon(&self) -> f32 {
        self.epsilon
    }

    /// Applies the functor kernel to the stored source.
    pub fn apply(&self) -> PureResult<Tensor> {
        self.source.matmul(&self.kernel)
    }

    /// Applies the functor kernel to an arbitrary functional.
    pub fn apply_to(&self, functional: &Tensor) -> PureResult<Tensor> {
        if functional.shape().1 != self.kernel.shape().0 {
            return Err(TensorError::ShapeMismatch {
                left: functional.shape(),
                right: self.kernel.shape(),
            });
        }
        functional.matmul(&self.kernel)
    }

    /// Finite-difference linearisation of the functor along `direction`.
    pub fn linearise(&self, direction: &Tensor) -> PureResult<Tensor> {
        if direction.shape() != self.source.shape() {
            return Err(TensorError::ShapeMismatch {
                left: direction.shape(),
                right: self.source.shape(),
            });
        }
        let scaled = direction.scale(self.epsilon)?;
        let displaced = self.source.add(&scaled)?;
        let base = self.apply()?;
        let lifted = displaced.matmul(&self.kernel)?;
        let diff = lifted.sub(&base)?;
        diff.scale(1.0 / self.epsilon)
    }
}

/// Recursive differential that follows the barycenter intermediate curve.
#[derive(Clone, Debug)]
pub struct RecursiveDifferential {
    barycenter: ZSpaceBarycenter,
}

impl RecursiveDifferential {
    /// Builds a recursive differential from a barycenter result.
    pub fn from_barycenter(barycenter: &ZSpaceBarycenter) -> Self {
        Self {
            barycenter: barycenter.clone(),
        }
    }

    /// Returns the barycenter density.
    pub fn density(&self) -> &Tensor {
        &self.barycenter.density
    }

    /// Objective curve sampled along the interpolation path.
    pub fn objective_curve(&self) -> Vec<f32> {
        self.barycenter
            .intermediates
            .iter()
            .map(|stage| stage.objective)
            .collect()
    }

    /// KL energy curve along the interpolation.
    pub fn kl_curve(&self) -> Vec<f32> {
        self.barycenter
            .intermediates
            .iter()
            .map(|stage| stage.kl_energy)
            .collect()
    }

    /// Entropy curve along the interpolation.
    pub fn entropy_curve(&self) -> Vec<f32> {
        self.barycenter
            .intermediates
            .iter()
            .map(|stage| stage.entropy)
            .collect()
    }

    fn curve_tensor(&self, values: &[f32], label: &'static str) -> PureResult<Tensor> {
        if values.is_empty() {
            return Err(TensorError::EmptyInput(label));
        }
        Tensor::from_vec(1, values.len(), values.to_vec())
    }

    /// Tensor form of the objective curve.
    pub fn objective_curve_tensor(&self) -> PureResult<Tensor> {
        let values = self.objective_curve();
        self.curve_tensor(&values, "recursive_objective")
    }

    /// Tensor form of the KL curve.
    pub fn kl_curve_tensor(&self) -> PureResult<Tensor> {
        let values = self.kl_curve();
        self.curve_tensor(&values, "recursive_kl")
    }

    /// Tensor form of the entropy curve.
    pub fn entropy_curve_tensor(&self) -> PureResult<Tensor> {
        let values = self.entropy_curve();
        self.curve_tensor(&values, "recursive_entropy")
    }

    /// Replays the barycenter intermediates into a hypergrad tape.
    pub fn accumulate(&self, hypergrad: &mut AmegaHypergrad) -> PureResult<()> {
        hypergrad.accumulate_barycenter_path(&self.barycenter.intermediates)
    }

    /// Returns a copy of the intermediate densities.
    pub fn intermediates(&self) -> &[BarycenterIntermediate] {
        &self.barycenter.intermediates
    }
}

/// Tower of tensors indexed by curvature levels (\(\infty\)-categorical shadow).
#[derive(Clone, Debug)]
pub struct InfinityDifferential {
    levels: Vec<Tensor>,
    curvatures: Vec<f32>,
}

impl InfinityDifferential {
    /// Builds a differential tower. `curvatures` may be empty to reuse the session curvature.
    pub fn new(levels: Vec<Tensor>, curvatures: Vec<f32>) -> PureResult<Self> {
        if levels.is_empty() {
            return Err(TensorError::EmptyInput("infinity_levels"));
        }
        if !curvatures.is_empty() && curvatures.len() != levels.len() {
            return Err(TensorError::DataLength {
                expected: levels.len(),
                got: curvatures.len(),
            });
        }
        Ok(Self { levels, curvatures })
    }

    /// Levels participating in the tower.
    pub fn levels(&self) -> &[Tensor] {
        &self.levels
    }

    /// Per-level curvatures.
    pub fn curvatures(&self) -> &[f32] {
        &self.curvatures
    }

    fn curvature_for(&self, idx: usize) -> f32 {
        if self.curvatures.is_empty() {
            1.0
        } else {
            self.curvatures[idx]
        }
    }

    /// Collapses the tower into an averaged tensor.
    pub fn collapse(&self) -> PureResult<Tensor> {
        let (rows, cols) = self.levels[0].shape();
        for level in &self.levels {
            if level.shape() != (rows, cols) {
                return Err(TensorError::ShapeMismatch {
                    left: level.shape(),
                    right: (rows, cols),
                });
            }
        }
        let mut accum = vec![0.0f32; rows * cols];
        for level in &self.levels {
            for (dest, value) in accum.iter_mut().zip(level.data()) {
                *dest += *value;
            }
        }
        let denom = self.levels.len() as f32;
        for dest in &mut accum {
            *dest /= denom;
        }
        Tensor::from_vec(rows, cols, accum)
    }

    /// Hierarchical energy (level norm scaled by curvature magnitude).
    pub fn hierarchical_energy_tensor(&self) -> PureResult<Tensor> {
        let mut values = Vec::with_capacity(self.levels.len());
        for (idx, level) in self.levels.iter().enumerate() {
            let curvature = self.curvature_for(idx).abs();
            values.push(level.squared_l2_norm() * curvature);
        }
        Tensor::from_vec(1, values.len(), values)
    }
}

/// Resonant snapshot produced by [`SpiralDifferential::resonate`].
#[derive(Clone, Debug)]
pub struct DifferentialResonance {
    pub homotopy_flow: Tensor,
    pub functor_linearisation: Tensor,
    pub recursive_objective: Tensor,
    pub infinity_projection: Tensor,
    pub infinity_energy: Tensor,
}

/// Unified differential surface combining homotopy, functor, recursive, and \(\infty\) towers.
#[derive(Clone, Debug)]
pub struct SpiralDifferential {
    topos: Option<OpenCartesianTopos>,
    homotopy: HomotopyDifferential,
    functor: FunctorDifferential,
    recursive: RecursiveDifferential,
    infinity: InfinityDifferential,
}

impl SpiralDifferential {
    /// Creates a new spiral differential.
    pub fn new(
        topos: Option<OpenCartesianTopos>,
        homotopy: HomotopyDifferential,
        functor: FunctorDifferential,
        recursive: RecursiveDifferential,
        infinity: InfinityDifferential,
    ) -> Self {
        Self {
            topos,
            homotopy,
            functor,
            recursive,
            infinity,
        }
    }

    /// Accessor for the homotopy differential.
    pub fn homotopy(&self) -> &HomotopyDifferential {
        &self.homotopy
    }

    /// Accessor for the functor differential.
    pub fn functor(&self) -> &FunctorDifferential {
        &self.functor
    }

    /// Accessor for the recursive differential.
    pub fn recursive(&self) -> &RecursiveDifferential {
        &self.recursive
    }

    /// Accessor for the \(\infty\)-tower differential.
    pub fn infinity(&self) -> &InfinityDifferential {
        &self.infinity
    }

    /// Runs the full resonance and optionally accumulates the recursive path into a hypergrad.
    pub fn resonate(
        &self,
        mut hypergrad: Option<&mut AmegaHypergrad>,
    ) -> PureResult<DifferentialResonance> {
        let mut homotopy_flow = self.homotopy.flow()?;
        let mut functor_linear = self.functor.linearise(self.homotopy.direction())?;
        let mut recursive_objective = self.recursive.objective_curve_tensor()?;
        let mut infinity_projection = self.infinity.collapse()?;
        let mut infinity_energy = self.infinity.hierarchical_energy_tensor()?;
        if let Some(topos) = &self.topos {
            topos.saturate_slice(homotopy_flow.data_mut());
            topos.guard_tensor("spiral_resonance_homotopy", &homotopy_flow)?;
            topos.saturate_slice(functor_linear.data_mut());
            topos.guard_tensor("spiral_resonance_functor", &functor_linear)?;
            topos.saturate_slice(recursive_objective.data_mut());
            topos.guard_tensor("spiral_resonance_objective", &recursive_objective)?;
            topos.saturate_slice(infinity_projection.data_mut());
            topos.guard_tensor("spiral_resonance_infinity", &infinity_projection)?;
            topos.saturate_slice(infinity_energy.data_mut());
            topos.guard_tensor("spiral_resonance_energy", &infinity_energy)?;
        }
        if let Some(hypergrad) = hypergrad.as_deref_mut() {
            self.recursive.accumulate(hypergrad)?;
        }
        Ok(DifferentialResonance {
            homotopy_flow,
            functor_linearisation: functor_linear,
            recursive_objective,
            infinity_projection,
            infinity_energy,
        })
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn toy_tensor(values: &[f32]) -> Tensor {
        Tensor::from_vec(1, values.len(), values.to_vec()).unwrap()
    }

    fn toy_stage(value: f32, density: &Tensor) -> BarycenterIntermediate {
        BarycenterIntermediate {
            interpolation: value,
            density: density.clone(),
            kl_energy: value * 0.5,
            entropy: value * 0.25,
            objective: value,
        }
    }

    #[test]
    fn spiral_differential_resonates() {
        let seed = toy_tensor(&[0.5, -0.2]);
        let generator = toy_tensor(&[1.0, -1.0]);
        let direction = toy_tensor(&[0.1, 0.4]);
        let homotopy = HomotopyDifferential::new(seed.clone(), generator, direction).unwrap();
        let kernel = Tensor::from_vec(2, 2, vec![1.0, 0.5, -0.5, 1.5]).unwrap();
        let functor = FunctorDifferential::new(seed.clone(), kernel, 0.01).unwrap();
        let density = toy_tensor(&[0.6, 0.4]);
        let stage_a = toy_stage(0.2, &density);
        let stage_b = toy_stage(0.8, &density);
        let barycenter = ZSpaceBarycenter {
            density: density.clone(),
            kl_energy: 0.1,
            entropy: 0.3,
            coupling_energy: 0.0,
            objective: 0.4,
            effective_weight: 1.0,
            intermediates: vec![stage_a, stage_b],
        };
        let recursive = RecursiveDifferential::from_barycenter(&barycenter);
        let infinity =
            InfinityDifferential::new(vec![density.clone(), density.clone()], vec![1.0, 2.0])
                .unwrap();
        let topos = OpenCartesianTopos::new(-1.0, 1e-4, 10.0, 8, 16).unwrap();
        let spiral = SpiralDifferential::new(Some(topos), homotopy, functor, recursive, infinity);
        let resonance = spiral.resonate(None).unwrap();
        assert_eq!(resonance.homotopy_flow.shape(), (1, 2));
        assert_eq!(resonance.functor_linearisation.shape(), (1, 2));
        assert_eq!(resonance.recursive_objective.shape().0, 1);
        assert_eq!(resonance.infinity_projection.shape(), (1, 2));
        assert_eq!(resonance.infinity_energy.shape().0, 1);
    }
}
