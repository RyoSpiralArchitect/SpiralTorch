# 3D Perception in SpiralTorch

The 3D pipeline is composed of three building blocks that can be mixed together
depending on whether an experiment requires CPU-only execution or GPU-accelerated
volume rendering.

## Field representation

`st-vision` exposes a lightweight [NeRF](https://arxiv.org/abs/2003.08934)
implementation built on top of the existing `st-nn` layers:

- **Positional encodings** live in `st_vision::nerf::PositionalEncoding` and
  expand 3D coordinates using the familiar sinusoidal basis. The number of
  frequency bands and whether to keep the raw coordinates can be configured
  when the encoder is constructed.
- **Backbone** networks are composed of the standard SpiralTorch
  `Linear` + `Relu` layers orchestrated by `Sequential`. `st_vision::nerf::NerfField`
  produces density and RGB predictions in a single pass while remaining fully
  compatible with the module/optimizer interfaces defined in `st-nn`.

The field exposes helpers to assemble batched inputs, so downstream code can
feed separate position/direction tensors without duplicating bookkeeping logic.

## Dataset adapters

Multi-view datasets can be expressed through `st_vision::datasets::MultiViewFrame`
and `MultiViewDatasetAdapter`. Frames keep per-ray origins, directions, RGB
supervision and near/far bounds. The adapter performs uniform-with-replacement
sampling over the registered frames, returning mini-batches ready for NeRF
training loops.

## Training loop

`st_vision::nerf::NerfTrainer` implements a CPU-side training loop that
handles stratified sampling, volumetric compositing and gradient accumulation on
NeRF fields. The trainer plugs into the existing module optimisers by using the
`Module` trait methods (`zero_accumulators`, `backward`, `apply_step`) exposed by
`st-nn`.

A small synthetic regression test (`crates/st-vision/tests/nerf_regression.rs`)
shows the trainer recovering the colour of a toy scene, providing a guardrail for
future refactors.

## GPU kernels

`st-backend-wgpu` now ships WGSL compute shaders that cover the most common
volumetric operations:

- `nerf_volume_utils.wgsl` generates stratified sample positions and segment
  lengths for a set of rays.
- `nerf_raymarch.wgsl` composites per-sample density/radiance predictions into
  final RGB and accumulated opacity buffers.

`crates/st-backend-wgpu/src/nerf.rs` exposes convenience constructors to load
these pipelines, so the higher level runtime can plug them into render graphs
without managing shader lifetimes manually.

Together these components let experiments span from CPU-only smoke tests to
fully hardware-accelerated reconstructions while remaining entirely within the
SpiralTorch ecosystem.
